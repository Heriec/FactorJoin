{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8594c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/CE_scheme\")\n",
    "from Schemas.stats.schema import gen_stats_light_schema\n",
    "from Evaluation.training import train_one_stats\n",
    "from Join_scheme.data_prepare import process_stats_data, update_stats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/ubuntu/End-to-End-CardEst-Benchmark/datasets/stats_simplified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7de3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_csv(table_obj, csv_seperator=',', stats=True):\n",
    "    \"\"\"\n",
    "    Reads csv from path, renames columns and drops unnecessary columns\n",
    "    \"\"\"\n",
    "    if stats:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location)\n",
    "    else:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location, header=None, escapechar='\\\\', encoding='utf-8',\n",
    "                              quotechar='\"',\n",
    "                              sep=csv_seperator)\n",
    "    df_rows.columns = [table_obj.table_name + '.' + attr for attr in table_obj.attributes]\n",
    "\n",
    "    for attribute in table_obj.irrelevant_attributes:\n",
    "        df_rows = df_rows.drop(table_obj.table_name + '.' + attribute, axis=1)\n",
    "\n",
    "    return df_rows.apply(pd.to_numeric, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def timestamp_transorform(time_string, start_date=\"2010-07-19 00:00:00\"):\n",
    "    start_date_int = time.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    time_array = time.strptime(time_string, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return int(time.mktime(time_array)) - int(time.mktime(start_date_int))\n",
    "\n",
    "\n",
    "def get_data_by_date(data_path, time_date=\"2014-01-01 00:00:00\"):\n",
    "    time_value = timestamp_transorform(time_date)\n",
    "    if not data_path.endswith(\".csv\"):\n",
    "        data_path += \"/{}.csv\"\n",
    "    schema = gen_stats_light_schema(data_path)\n",
    "    before_data = dict()\n",
    "    after_data = dict()\n",
    "    for table_obj in schema.tables:\n",
    "        table_name = table_obj.table_name\n",
    "        df_rows = read_table_csv(table_obj)\n",
    "        idx = len(df_rows)\n",
    "        for attribute in df_rows.columns:\n",
    "            if \"Date\" in attribute:\n",
    "                idx = np.searchsorted(df_rows[attribute].values, time_value)\n",
    "                break\n",
    "                \n",
    "        before_data[table_name] = df_rows[:idx] if idx > 0 else None\n",
    "        after_data[table_name] = df_rows[idx:] if idx < len(df_rows) else None\n",
    "    return before_data, after_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c66e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_data, after_data = get_data_by_date(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b1c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketizing equivalent key group: {'votes.PostId', 'postHistory.PostId', 'posts.Id', 'comments.PostId', 'postLinks.RelatedPostId', 'postLinks.PostId', 'tags.ExcerptPostId'}\n",
      "bucketizing equivalent key group: {'users.Id', 'postHistory.UserId', 'votes.UserId', 'posts.OwnerUserId', 'comments.UserId', 'badges.UserId'}\n",
      "badges\n",
      "Discretizing table takes 0.019681930541992188 secs\n",
      "Structure learning took 1.2572910785675049 secs.\n",
      "done, parameter learning took 0.12844324111938477 secs.\n",
      "votes\n",
      "Discretizing table takes 2.4132630825042725 secs\n",
      "Structure learning took 11.587518692016602 secs.\n",
      "done, parameter learning took 0.10096120834350586 secs.\n",
      "postHistory\n",
      "Discretizing table takes 0.10354423522949219 secs\n",
      "Structure learning took 13.76157522201538 secs.\n",
      "done, parameter learning took 0.2123408317565918 secs.\n",
      "posts\n",
      "Discretizing table takes 0.4966287612915039 secs\n",
      "Structure learning took 11.83762264251709 secs.\n",
      "done, parameter learning took 0.24127769470214844 secs.\n",
      "users\n",
      "Discretizing table takes 3.013062000274658 secs\n",
      "Structure learning took 2.9102323055267334 secs.\n",
      "done, parameter learning took 0.09412908554077148 secs.\n",
      "comments\n",
      "Discretizing table takes 0.08690738677978516 secs\n",
      "Structure learning took 7.232367038726807 secs.\n",
      "done, parameter learning took 0.14689254760742188 secs.\n",
      "postLinks\n",
      "Discretizing table takes 0.03362774848937988 secs\n",
      "Structure learning took 0.6554694175720215 secs.\n",
      "done, parameter learning took 0.08240413665771484 secs.\n",
      "tags\n",
      "Discretizing table takes 0.009711503982543945 secs\n",
      "Structure learning took 0.07833075523376465 secs.\n",
      "done, parameter learning took 0.019107818603515625 secs.\n",
      "models save at /home/ubuntu/data_CE/CE_scheme_models/update/model_stats_sub_optimal_200.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/ubuntu/data_CE/CE_scheme_models/update/\"\n",
    "train_one_stats(\"stats\", data_folder, model_path, 200, \"sub_optimal\", True, actual_data=before_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb0bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path + \"buckets.pkl\", \"rb\") as f:\n",
    "    buckets = pickle.load(f)\n",
    "with open(model_path + \"model_stats_sub_optimal_200.pkl\", \"rb\") as f:\n",
    "    FJmodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/home/ubuntu/End-to-End-CardEst-Benchmark/workloads/stats_CEB/sub_plan_queries/stats_CEB_sub_queries.sql\"\n",
    "with open(query_file, \"r\") as f:\n",
    "    queries = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qerror = []\n",
    "latency = []\n",
    "pred = []\n",
    "for i, query_str in enumerate(queries):\n",
    "    query = query_str.split(\"||\")[0][:-1]\n",
    "    print(\"========================\")\n",
    "    true_card = int(query_str.split(\"||\")[-1])\n",
    "    t = time.time()\n",
    "    res = FJmodel.get_cardinality_bound(query)\n",
    "    pred.append(res)\n",
    "    latency.append(time.time() - t)\n",
    "    qerror.append(res/true_card)\n",
    "    print(f\"estimating query {i}: predicted {res}, true_card {true_card}, qerror {res/true_card}, latency {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372bf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99, 100]:\n",
    "    print(f\"q-error {i}% percentile is {np.percentile(qerror, i)}\")\n",
    "print(f\"total inference time: {np.sum(latency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3b6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags does not have data to update\n",
      "updating equivalent key group: {'votes.PostId', 'postHistory.PostId', 'posts.Id', 'comments.PostId', 'postLinks.RelatedPostId', 'postLinks.PostId', 'tags.ExcerptPostId'}\n",
      "tags.ExcerptPostId\n",
      "updating equivalent key group: {'users.Id', 'postHistory.UserId', 'votes.UserId', 'posts.OwnerUserId', 'comments.UserId', 'badges.UserId'}\n"
     ]
    }
   ],
   "source": [
    "table_buckets = FJmodel.table_buckets\n",
    "null_values = FJmodel.null_value\n",
    "data, table_buckets, null_values = update_stats_data(data_folder, model_path, buckets, table_buckets,\n",
    "                                                     null_values, False, after_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BayesCard.Models.Bayescard_BN import Bayescard_BN\n",
    "\n",
    "\n",
    "all_bns = dict()\n",
    "for table in FJmodel.schema.tables:\n",
    "    t_name = table.table_name\n",
    "    print(t_name)\n",
    "    if t_name in data and data[t_name] is not None:\n",
    "        bn = Bayescard_BN(t_name, table_buckets[t_name].id_attributes, table_buckets[t_name].bin_sizes,\n",
    "                          null_values=null_values[t_name])\n",
    "        new_data = before_data[t_name].append(data[t_name], ignore_index=True)\n",
    "        print(len(new_data), new_data.columns)\n",
    "        bn.build_from_data(new_data)\n",
    "        FJmodel.bns[t_name] = bn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c9157a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Bayescard_BN' object has no attribute 'fanout_attr_inverse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9e082cb4ed2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFJmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CE_scheme/BayesCard/Models/Bayescard_BN.py\u001b[0m in \u001b[0;36mupdate_from_data\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdiscrete_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_update_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Discretizing table took {time.time() - t} secs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CE_scheme/BayesCard/Models/BN_single_model.py\u001b[0m in \u001b[0;36mprocess_update_dataset\u001b[0;34m(self, data, n_bins, drop_na, ignore_cols)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfanout_attr_inverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfanout_attr_positive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Bayescard_BN' object has no attribute 'fanout_attr_inverse'"
     ]
    }
   ],
   "source": [
    "for table in FJmodel.schema.tables:\n",
    "    t_name = table.table_name\n",
    "    if t_name in data and data[t_name] is not None:\n",
    "        bn = FJmodel.bns[t_name]\n",
    "        bn.null_values = null_values[t_name]\n",
    "        bn.update_from_data(data[t_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5527b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
