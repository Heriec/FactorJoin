{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8594c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/CE_scheme\")\n",
    "from Schemas.stats.schema import gen_stats_light_schema\n",
    "from Evaluation.training import train_one_stats, test_trained_BN_on_stats\n",
    "from Join_scheme.data_prepare import process_stats_data, update_stats_data\n",
    "from BayesCard.Models.Bayescard_BN import Bayescard_BN\n",
    "from BayesCard.Evaluation.cardinality_estimation import parse_query_single_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/ubuntu/End-to-End-CardEst-Benchmark/datasets/stats_simplified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7de3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_csv(table_obj, csv_seperator=',', stats=True):\n",
    "    \"\"\"\n",
    "    Reads csv from path, renames columns and drops unnecessary columns\n",
    "    \"\"\"\n",
    "    if stats:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location)\n",
    "    else:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location, header=None, escapechar='\\\\', encoding='utf-8',\n",
    "                              quotechar='\"',\n",
    "                              sep=csv_seperator)\n",
    "    df_rows.columns = [table_obj.table_name + '.' + attr for attr in table_obj.attributes]\n",
    "\n",
    "    for attribute in table_obj.irrelevant_attributes:\n",
    "        df_rows = df_rows.drop(table_obj.table_name + '.' + attribute, axis=1)\n",
    "\n",
    "    return df_rows.apply(pd.to_numeric, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def timestamp_transorform(time_string, start_date=\"2010-07-19 00:00:00\"):\n",
    "    start_date_int = time.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    time_array = time.strptime(time_string, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return int(time.mktime(time_array)) - int(time.mktime(start_date_int))\n",
    "\n",
    "\n",
    "def get_data_by_date(data_path, time_date=\"2014-01-01 00:00:00\"):\n",
    "    time_value = timestamp_transorform(time_date)\n",
    "    if not data_path.endswith(\".csv\"):\n",
    "        data_path += \"/{}.csv\"\n",
    "    schema = gen_stats_light_schema(data_path)\n",
    "    before_data = dict()\n",
    "    after_data = dict()\n",
    "    for table_obj in schema.tables:\n",
    "        table_name = table_obj.table_name\n",
    "        df_rows = read_table_csv(table_obj)\n",
    "        idx = len(df_rows)\n",
    "        for attribute in df_rows.columns:\n",
    "            if \"Date\" in attribute:\n",
    "                idx = np.searchsorted(df_rows[attribute].values, time_value)\n",
    "                break\n",
    "                \n",
    "        before_data[table_name] = df_rows[:idx] if idx > 0 else None\n",
    "        after_data[table_name] = df_rows[idx:] if idx < len(df_rows) else None\n",
    "    return before_data, after_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c66e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_data, after_data = get_data_by_date(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d630dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/ubuntu/data_CE/CE_scheme_models/update/\"\n",
    "data, null_values, key_attrs, table_buckets, equivalent_keys, schema, bin_size = process_stats_data(data_folder,\n",
    "                                        model_path, 200, \"sub_optimal\", False, data=before_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01919931",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_name = \"postHistory\"\n",
    "bn = Bayescard_BN(t_name, key_attrs[t_name], bin_size[t_name], null_values=null_values[t_name])\n",
    "bn.build_from_data(data[t_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b1c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketizing equivalent key group: {'postHistory.PostId', 'postLinks.RelatedPostId', 'posts.Id', 'postLinks.PostId', 'tags.ExcerptPostId', 'comments.PostId', 'votes.PostId'}\n",
      "bucketizing equivalent key group: {'votes.UserId', 'badges.UserId', 'posts.OwnerUserId', 'postHistory.UserId', 'users.Id', 'comments.UserId'}\n",
      "badges\n",
      "Discretizing table takes 0.020223140716552734 secs\n",
      "Structure learning took 1.2931559085845947 secs.\n",
      "done, parameter learning took 0.07734131813049316 secs.\n",
      "votes\n",
      "Discretizing table takes 2.4802844524383545 secs\n",
      "Structure learning took 11.316552639007568 secs.\n",
      "done, parameter learning took 0.10006475448608398 secs.\n",
      "postHistory\n",
      "Discretizing table takes 0.09330105781555176 secs\n",
      "Structure learning took 12.711439609527588 secs.\n",
      "done, parameter learning took 0.21827101707458496 secs.\n",
      "posts\n",
      "Discretizing table takes 0.4853363037109375 secs\n",
      "Structure learning took 11.590935230255127 secs.\n",
      "done, parameter learning took 0.2164306640625 secs.\n",
      "users\n",
      "Discretizing table takes 2.4798812866210938 secs\n",
      "Structure learning took 2.5951852798461914 secs.\n",
      "done, parameter learning took 0.09134626388549805 secs.\n",
      "comments\n",
      "Discretizing table takes 0.08761405944824219 secs\n",
      "Structure learning took 7.097137689590454 secs.\n",
      "done, parameter learning took 0.1391284465789795 secs.\n",
      "postLinks\n",
      "Discretizing table takes 0.015556573867797852 secs\n",
      "Structure learning took 0.5820364952087402 secs.\n",
      "done, parameter learning took 0.07914495468139648 secs.\n",
      "tags\n",
      "Discretizing table takes 0.009625673294067383 secs\n",
      "Structure learning took 0.026538610458374023 secs.\n",
      "done, parameter learning took 0.018077373504638672 secs.\n",
      "models save at /home/ubuntu/data_CE/CE_scheme_models/update/model_stats_sub_optimal_200.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/ubuntu/data_CE/CE_scheme_models/update/\"\n",
    "train_one_stats(\"stats\", data_folder, model_path, 200, \"sub_optimal\", True, actual_data=before_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb0bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path + \"buckets.pkl\", \"rb\") as f:\n",
    "    buckets = pickle.load(f)\n",
    "with open(model_path + \"model_stats_sub_optimal_200.pkl\", \"rb\") as f:\n",
    "    FJmodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/home/ubuntu/End-to-End-CardEst-Benchmark/workloads/stats_CEB/sub_plan_queries/stats_CEB_sub_queries.sql\"\n",
    "with open(query_file, \"r\") as f:\n",
    "    queries = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c67bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qerror = []\n",
    "latency = []\n",
    "pred = []\n",
    "for i, query_str in enumerate(queries):\n",
    "    query = query_str.split(\"||\")[0][:-1]\n",
    "    print(\"========================\")\n",
    "    true_card = int(query_str.split(\"||\")[-1])\n",
    "    t = time.time()\n",
    "    res = FJmodel.get_cardinality_bound(query)\n",
    "    pred.append(res)\n",
    "    latency.append(time.time() - t)\n",
    "    qerror.append(res/true_card)\n",
    "    print(f\"estimating query {i}: predicted {res}, true_card {true_card}, qerror {res/true_card}, latency {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99, 100]:\n",
    "    print(f\"q-error {i}% percentile is {np.percentile(qerror, i)}\")\n",
    "print(f\"total inference time: {np.sum(latency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3b6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags does not have data to update\n",
      "updating equivalent key group: {'postHistory.PostId', 'postLinks.RelatedPostId', 'posts.Id', 'postLinks.PostId', 'tags.ExcerptPostId', 'comments.PostId', 'votes.PostId'}\n",
      "tags.ExcerptPostId\n",
      "updating equivalent key group: {'votes.UserId', 'badges.UserId', 'posts.OwnerUserId', 'postHistory.UserId', 'users.Id', 'comments.UserId'}\n"
     ]
    }
   ],
   "source": [
    "table_buckets = FJmodel.table_buckets\n",
    "null_values = FJmodel.null_value\n",
    "data, table_buckets, null_values = update_stats_data(data_folder, model_path, buckets, table_buckets,\n",
    "                                                     null_values, False, after_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3086cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trained_BN_on_stats(bn, t_name):\n",
    "    queries = {\n",
    "        \"posts\": \"SELECT COUNT(*) FROM posts as p WHERE posts.CommentCount<=18 AND posts.CreationDate>='2010-07-23 07:27:31'::timestamp AND posts.CreationDate<='2014-09-09 01:43:00'::timestamp\",\n",
    "        \"comments\": \"SELECT COUNT(*) FROM comments as c WHERE comments.CreationDate>='2010-08-05 00:36:02'::timestamp AND comments.CreationDate<='2014-09-08 16:50:49'::timestamp\",\n",
    "        \"postHistory\": \"SELECT COUNT(*) FROM postHistory as ph WHERE postHistory.PostHistoryTypeId=1 AND postHistory.CreationDate>='2010-09-14 11:59:07'::timestamp\",\n",
    "        \"votes\": \"SELECT COUNT(*) FROM votes as v WHERE votes.VoteTypeId=2 AND votes.CreationDate<='2014-09-10 00:00:00'::timestamp\",\n",
    "        \"postLinks\": \"SELECT COUNT(*) FROM postLinks as pl WHERE postLinks.LinkTypeId=1 AND postLinks.CreationDate>='2011-09-03 21:00:10'::timestamp AND postLinks.CreationDate<='2014-07-30 21:29:52'::timestamp\",\n",
    "        \"users\": \"SELECT COUNT(*) FROM users as u WHERE users.DownVotes>=0 AND users.DownVotes<=0 AND users.UpVotes>=0 AND users.UpVotes<=31 AND users.CreationDate<='2014-08-06 20:38:52'::timestamp\",\n",
    "        \"badges\": \"SELECT COUNT(*) FROM badges as b WHERE badges.Date>='2010-09-26 12:17:14'::timestamp\",\n",
    "        \"tags\": \"SELECT COUNT(*) FROM tags\"\n",
    "    }\n",
    "\n",
    "    true_cards = {\n",
    "        \"posts\": 90764,\n",
    "        \"comments\": 172156,\n",
    "        \"postHistory\": 42308,\n",
    "        \"votes\": 261476,\n",
    "        \"postLinks\": 8776,\n",
    "        \"users\": 37062,\n",
    "        \"badges\": 77704,\n",
    "        \"tags\": 1032\n",
    "    }\n",
    "\n",
    "    bn.init_inference_method()\n",
    "    bn.infer_algo = \"exact-jit\"\n",
    "    query = parse_query_single_table(queries[t_name], bn)\n",
    "    pred = bn.query(query)\n",
    "    print(pred)\n",
    "    assert min(pred, true_cards[t_name]) / max(pred, true_cards[t_name]) <= 1.5, f\"Qerror too large, we have predition\" \\\n",
    "                                                                        f\"{pred} for true card {true_cards[t_name]}\"\n",
    "\n",
    "    query = parse_query_single_table(queries[t_name], bn)\n",
    "    _, id_probs = bn.query_id_prob(query, bn.id_attributes)\n",
    "    print(np.sum(id_probs))\n",
    "    if t_name not in ['votes', 'tags']:\n",
    "        assert min(pred, np.sum(id_probs)) / max(pred, np.sum(id_probs)) <= 1.5, \"query_id_prob is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed45d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_name = \"postHistory\"\n",
    "bn = FJmodel.bns[t_name]\n",
    "bn.null_values = null_values[t_name]\n",
    "print(len(data[t_name]))\n",
    "bn.update_from_data(data[t_name])\n",
    "test_trained_BN_on_stats(bn, t_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0cc589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "badges\n",
      "Discretizing table took 0.03995180130004883 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for badges.Date\n",
      "WARNING:root:Replacing existing CPD for badges.UserId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.17960119247436523 secs.\n",
      "votes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for votes.BountyAmount\n",
      "WARNING:root:Replacing existing CPD for votes.CreationDate\n",
      "WARNING:root:Replacing existing CPD for votes.PostId\n",
      "WARNING:root:Replacing existing CPD for votes.UserId\n",
      "WARNING:root:Replacing existing CPD for votes.VoteTypeId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.6610567569732666 secs.\n",
      "done, incremental parameter updating took 0.1657705307006836 secs.\n",
      "postHistory\n",
      "Discretizing table took 0.0810699462890625 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for postHistory.CreationDate\n",
      "WARNING:root:Replacing existing CPD for postHistory.PostHistoryTypeId\n",
      "WARNING:root:Replacing existing CPD for postHistory.PostId\n",
      "WARNING:root:Replacing existing CPD for postHistory.UserId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.30565738677978516 secs.\n",
      "posts\n",
      "Discretizing table took 0.41088366508483887 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for posts.AnswerCount\n",
      "WARNING:root:Replacing existing CPD for posts.CommentCount\n",
      "WARNING:root:Replacing existing CPD for posts.CreationDate\n",
      "WARNING:root:Replacing existing CPD for posts.FavoriteCount\n",
      "WARNING:root:Replacing existing CPD for posts.Id\n",
      "WARNING:root:Replacing existing CPD for posts.OwnerUserId\n",
      "WARNING:root:Replacing existing CPD for posts.PostTypeId\n",
      "WARNING:root:Replacing existing CPD for posts.Score\n",
      "WARNING:root:Replacing existing CPD for posts.ViewCount\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.4997742176055908 secs.\n",
      "users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for users.CreationDate\n",
      "WARNING:root:Replacing existing CPD for users.DownVotes\n",
      "WARNING:root:Replacing existing CPD for users.Id\n",
      "WARNING:root:Replacing existing CPD for users.Reputation\n",
      "WARNING:root:Replacing existing CPD for users.UpVotes\n",
      "WARNING:root:Replacing existing CPD for users.Views\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.9261248111724854 secs.\n",
      "done, incremental parameter updating took 0.19570565223693848 secs.\n",
      "comments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for comments.CreationDate\n",
      "WARNING:root:Replacing existing CPD for comments.PostId\n",
      "WARNING:root:Replacing existing CPD for comments.Score\n",
      "WARNING:root:Replacing existing CPD for comments.UserId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.06556344032287598 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for postLinks.CreationDate\n",
      "WARNING:root:Replacing existing CPD for postLinks.LinkTypeId\n",
      "WARNING:root:Replacing existing CPD for postLinks.PostId\n",
      "WARNING:root:Replacing existing CPD for postLinks.RelatedPostId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.2619166374206543 secs.\n",
      "postLinks\n",
      "Discretizing table took 0.024054527282714844 secs.\n",
      "done, incremental parameter updating took 0.1285252571105957 secs.\n",
      "tags\n"
     ]
    }
   ],
   "source": [
    "for table in FJmodel.schema.tables:\n",
    "    t_name = table.table_name\n",
    "    print(t_name)\n",
    "    if t_name in data and data[t_name] is not None:\n",
    "        bn = FJmodel.bns[t_name]\n",
    "        bn.null_values = null_values[t_name]\n",
    "        bn.update_from_data(data[t_name])\n",
    "        #test_trained_BN_on_stats(bn, t_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,2,3,]\n",
    "a.remove(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "a = a.delete(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c8f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/CE_scheme\")\n",
    "from Schemas.stats.schema import gen_stats_light_schema\n",
    "from Evaluation.training import train_one_stats, test_trained_BN_on_stats\n",
    "from Join_scheme.data_prepare import read_table_csv, update_stats_data\n",
    "from BayesCard.Models.Bayescard_BN import Bayescard_BN\n",
    "\n",
    "\n",
    "def timestamp_transorform(time_string, start_date=\"2010-07-19 00:00:00\"):\n",
    "    start_date_int = time.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    time_array = time.strptime(time_string, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return int(time.mktime(time_array)) - int(time.mktime(start_date_int))\n",
    "\n",
    "\n",
    "def get_data_by_date(data_path, time_date=\"2014-01-01 00:00:00\"):\n",
    "    time_value = timestamp_transorform(time_date)\n",
    "    if not data_path.endswith(\".csv\"):\n",
    "        data_path += \"/{}.csv\"\n",
    "    schema = gen_stats_light_schema(data_path)\n",
    "    before_data = dict()\n",
    "    after_data = dict()\n",
    "    for table_obj in schema.tables:\n",
    "        table_name = table_obj.table_name\n",
    "        df_rows = read_table_csv(table_obj)\n",
    "        idx = len(df_rows)\n",
    "        for attribute in df_rows.columns:\n",
    "            if \"Date\" in attribute:\n",
    "                idx = np.searchsorted(df_rows[attribute].values, time_value)\n",
    "                break\n",
    "\n",
    "        before_data[table_name] = df_rows[:idx] if idx > 0 else None\n",
    "        after_data[table_name] = df_rows[idx:] if idx < len(df_rows) else None\n",
    "    return before_data, after_data\n",
    "\n",
    "\n",
    "def update_one_stats(FJmodel, buckets, table_buckets, data_path, save_model_folder, save_bucket_bins=False,\n",
    "                     update_BN=True, retrain_BN=False, old_data=None, validate=False):\n",
    "    \"\"\"\n",
    "    Incrementally update the FactorJoin model\n",
    "    \"\"\"\n",
    "    data, table_buckets, null_values = update_stats_data(data_path, save_model_folder, buckets, table_buckets,\n",
    "                                                         save_bucket_bins)\n",
    "    FJmodel.table_buckets = table_buckets\n",
    "    if update_BN:\n",
    "        # updating the single table estimator\n",
    "        if retrain_BN:\n",
    "            # retrain the BN based on the new and old data\n",
    "            for table in FJmodel.schema.tables:\n",
    "                t_name = table.table_name\n",
    "                if t_name in data and data[t_name] is not None:\n",
    "                    bn = Bayescard_BN(t_name, table_buckets[t_name].id_attributes, table_buckets[t_name].bin_sizes,\n",
    "                                      null_values=null_values[t_name])\n",
    "                    new_data = old_data[t_name].append(data[t_name], ignore_index=True)\n",
    "                    bn.build_from_data(new_data)\n",
    "                    if validate:\n",
    "                        test_trained_BN_on_stats(bn, t_name)\n",
    "                    FJmodel.bns[t_name] = bn\n",
    "        else:\n",
    "            # incrementally update BN\n",
    "            for table in FJmodel.schema.tables:\n",
    "                t_name = table.table_name\n",
    "                if t_name in data and data[t_name] is not None:\n",
    "                    bn = FJmodel.bns[t_name]\n",
    "                    bn.null_values = null_values[t_name]\n",
    "                    bn.update_from_data(data)\n",
    "\n",
    "    model_path = save_model_folder + f\"update_model.pkl\"\n",
    "    pickle.dump(FJmodel, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"models save at {model_path}\")\n",
    "\n",
    "\n",
    "def eval_update(data_folder, model_path, bin_size, bucket_method, split_date=\"2014-01-01 00:00:00\"):\n",
    "    before_data, after_data = get_data_by_date(data_folder, split_date)\n",
    "    print(\"************************************************************\")\n",
    "    print(f\"Training the model with data before {split_date}\")\n",
    "    start_time = time.time()\n",
    "    train_one_stats(\"stats\", data_folder, model_path, bin_size, bucket_method, True, actual_data=before_data)\n",
    "    print(f\"training completed, took {time.time() - start_time} sec\")\n",
    "\n",
    "    #loading the trained model and buckets\n",
    "    with open(model_path + \"buckets.pkl\", \"rb\") as f:\n",
    "        buckets = pickle.load(f)\n",
    "    with open(model_path + f\"model_stats_{bucket_method}_{bin_size}.pkl\", \"rb\") as f:\n",
    "        FJmodel = pickle.load(f)\n",
    "    print(\"************************************************************\")\n",
    "    print(f\"Updating the model with data after {split_date}\")\n",
    "    start_time = time.time()\n",
    "    table_buckets = FJmodel.table_buckets\n",
    "    null_values = FJmodel.null_value\n",
    "    data, table_buckets, null_values = update_stats_data(data_folder, model_path, buckets, table_buckets,\n",
    "                                                         null_values, False, after_data)\n",
    "    for table in FJmodel.schema.tables:\n",
    "        t_name = table.table_name\n",
    "        if t_name in data and data[t_name] is not None:\n",
    "            bn = FJmodel.bns[t_name]\n",
    "            bn.null_values = null_values[t_name]\n",
    "            bn.update_from_data(data[t_name])\n",
    "            #test_trained_BN_on_stats(bn, t_name)\n",
    "    print(f\"updating completed, took {time.time() - start_time} sec\")\n",
    "    model_path = model_path + f\"updated_model_stats_{bucket_method}_{bin_size}.pkl\"\n",
    "    pickle.dump(FJmodel, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"updated models save at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de1e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Training the model with data before 2014-01-01 00:00:00\n",
      "bucketizing equivalent key group: {'postHistory.PostId', 'postLinks.RelatedPostId', 'posts.Id', 'postLinks.PostId', 'tags.ExcerptPostId', 'comments.PostId', 'votes.PostId'}\n",
      "bucketizing equivalent key group: {'votes.UserId', 'badges.UserId', 'posts.OwnerUserId', 'postHistory.UserId', 'users.Id', 'comments.UserId'}\n",
      "badges\n",
      "Discretizing table takes 0.015857696533203125 secs\n",
      "Structure learning took 1.1505992412567139 secs.\n",
      "done, parameter learning took 0.06596612930297852 secs.\n",
      "votes\n",
      "Discretizing table takes 2.3427138328552246 secs\n",
      "Structure learning took 10.038585186004639 secs.\n",
      "done, parameter learning took 0.18168926239013672 secs.\n",
      "postHistory\n",
      "Discretizing table takes 0.1303114891052246 secs\n",
      "Structure learning took 13.11159086227417 secs.\n",
      "done, parameter learning took 0.2548544406890869 secs.\n",
      "posts\n",
      "Discretizing table takes 0.6537225246429443 secs\n",
      "Structure learning took 10.32241702079773 secs.\n",
      "done, parameter learning took 0.3276209831237793 secs.\n",
      "users\n",
      "Discretizing table takes 2.991630792617798 secs\n",
      "Structure learning took 2.860927104949951 secs.\n",
      "done, parameter learning took 0.1603085994720459 secs.\n",
      "comments\n",
      "Discretizing table takes 0.11858916282653809 secs\n",
      "Structure learning took 6.409207105636597 secs.\n",
      "done, parameter learning took 0.1287994384765625 secs.\n",
      "postLinks\n",
      "Discretizing table takes 0.0372309684753418 secs\n",
      "Structure learning took 0.8696367740631104 secs.\n",
      "done, parameter learning took 0.081451416015625 secs.\n",
      "tags\n",
      "Discretizing table takes 0.009355783462524414 secs\n",
      "Structure learning took 0.02651357650756836 secs.\n",
      "done, parameter learning took 0.01805424690246582 secs.\n",
      "models save at /home/ubuntu/data_CE/CE_scheme_models/update/model_stats_sub_optimal_200.pkl\n",
      "training completed, took 59.704742193222046 sec\n",
      "************************************************************\n",
      "Updating the model with data after 2014-01-01 00:00:00\n",
      "tags does not have data to update\n",
      "updating equivalent key group: {'postHistory.PostId', 'postLinks.RelatedPostId', 'posts.Id', 'postLinks.PostId', 'tags.ExcerptPostId', 'comments.PostId', 'votes.PostId'}\n",
      "tags.ExcerptPostId\n",
      "updating equivalent key group: {'votes.UserId', 'badges.UserId', 'posts.OwnerUserId', 'postHistory.UserId', 'users.Id', 'comments.UserId'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for badges.Date\n",
      "WARNING:root:Replacing existing CPD for badges.UserId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.01146245002746582 secs.\n",
      "done, incremental parameter updating took 0.09986567497253418 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for votes.BountyAmount\n",
      "WARNING:root:Replacing existing CPD for votes.CreationDate\n",
      "WARNING:root:Replacing existing CPD for votes.PostId\n",
      "WARNING:root:Replacing existing CPD for votes.UserId\n",
      "WARNING:root:Replacing existing CPD for votes.VoteTypeId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.45528507232666016 secs.\n",
      "done, incremental parameter updating took 0.0971364974975586 secs.\n",
      "Discretizing table took 0.057456016540527344 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for postHistory.CreationDate\n",
      "WARNING:root:Replacing existing CPD for postHistory.PostHistoryTypeId\n",
      "WARNING:root:Replacing existing CPD for postHistory.PostId\n",
      "WARNING:root:Replacing existing CPD for postHistory.UserId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.2699098587036133 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for posts.AnswerCount\n",
      "WARNING:root:Replacing existing CPD for posts.CommentCount\n",
      "WARNING:root:Replacing existing CPD for posts.CreationDate\n",
      "WARNING:root:Replacing existing CPD for posts.FavoriteCount\n",
      "WARNING:root:Replacing existing CPD for posts.Id\n",
      "WARNING:root:Replacing existing CPD for posts.OwnerUserId\n",
      "WARNING:root:Replacing existing CPD for posts.PostTypeId\n",
      "WARNING:root:Replacing existing CPD for posts.Score\n",
      "WARNING:root:Replacing existing CPD for posts.ViewCount\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.21903753280639648 secs.\n",
      "done, incremental parameter updating took 0.24938750267028809 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for users.CreationDate\n",
      "WARNING:root:Replacing existing CPD for users.DownVotes\n",
      "WARNING:root:Replacing existing CPD for users.Id\n",
      "WARNING:root:Replacing existing CPD for users.Reputation\n",
      "WARNING:root:Replacing existing CPD for users.UpVotes\n",
      "WARNING:root:Replacing existing CPD for users.Views\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing table took 0.5899736881256104 secs.\n",
      "done, incremental parameter updating took 0.1284177303314209 secs.\n",
      "Discretizing table took 0.04863405227661133 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for comments.CreationDate\n",
      "WARNING:root:Replacing existing CPD for comments.PostId\n",
      "WARNING:root:Replacing existing CPD for comments.Score\n",
      "WARNING:root:Replacing existing CPD for comments.UserId\n",
      "WARNING:root:Replacing existing CPD for postLinks.CreationDate\n",
      "WARNING:root:Replacing existing CPD for postLinks.LinkTypeId\n",
      "WARNING:root:Replacing existing CPD for postLinks.PostId\n",
      "WARNING:root:Replacing existing CPD for postLinks.RelatedPostId\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, incremental parameter updating took 0.2456510066986084 secs.\n",
      "Discretizing table took 0.014635086059570312 secs.\n",
      "done, incremental parameter updating took 0.09695196151733398 secs.\n",
      "updating completed, took 4.804568529129028 sec\n",
      "updated models save at /home/ubuntu/data_CE/CE_scheme_models/update/updated_model_stats_sub_optimal_200.pkl\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/ubuntu/End-to-End-CardEst-Benchmark/datasets/stats_simplified\"\n",
    "model_path = \"/home/ubuntu/data_CE/CE_scheme_models/update/\"\n",
    "eval_update(data_path, model_path, 200, \"sub_optimal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371f1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
