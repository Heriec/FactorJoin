{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8594c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/CE_scheme\")\n",
    "from Schemas.stats.schema import gen_stats_light_schema\n",
    "from Evaluation.training import train_one_stats\n",
    "from Join_scheme.data_prepare import process_stats_data, update_stats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/ubuntu/End-to-End-CardEst-Benchmark/datasets/stats_simplified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7de3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_csv(table_obj, csv_seperator=',', stats=True):\n",
    "    \"\"\"\n",
    "    Reads csv from path, renames columns and drops unnecessary columns\n",
    "    \"\"\"\n",
    "    if stats:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location)\n",
    "    else:\n",
    "        df_rows = pd.read_csv(table_obj.csv_file_location, header=None, escapechar='\\\\', encoding='utf-8',\n",
    "                              quotechar='\"',\n",
    "                              sep=csv_seperator)\n",
    "    df_rows.columns = [table_obj.table_name + '.' + attr for attr in table_obj.attributes]\n",
    "\n",
    "    for attribute in table_obj.irrelevant_attributes:\n",
    "        df_rows = df_rows.drop(table_obj.table_name + '.' + attribute, axis=1)\n",
    "\n",
    "    return df_rows.apply(pd.to_numeric, errors=\"ignore\")\n",
    "\n",
    "\n",
    "def timestamp_transorform(time_string, start_date=\"2010-07-19 00:00:00\"):\n",
    "    start_date_int = time.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    time_array = time.strptime(time_string, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return int(time.mktime(time_array)) - int(time.mktime(start_date_int))\n",
    "\n",
    "\n",
    "def get_data_by_date(data_path, time_date=\"2014-01-01 00:00:00\"):\n",
    "    time_value = timestamp_transorform(time_date)\n",
    "    if not data_path.endswith(\".csv\"):\n",
    "        data_path += \"/{}.csv\"\n",
    "    schema = gen_stats_light_schema(data_path)\n",
    "    before_data = dict()\n",
    "    after_data = dict()\n",
    "    for table_obj in schema.tables:\n",
    "        table_name = table_obj.table_name\n",
    "        df_rows = read_table_csv(table_obj)\n",
    "        idx = len(df_rows)\n",
    "        for attribute in df_rows.columns:\n",
    "            if \"Date\" in attribute:\n",
    "                idx = np.searchsorted(df_rows[attribute].values, time_value)\n",
    "                break\n",
    "                \n",
    "        before_data[table_name] = df_rows[:idx] if idx > 0 else None\n",
    "        after_data[table_name] = df_rows[idx:] if idx < len(df_rows) else None\n",
    "    return before_data, after_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c66e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_data, after_data = get_data_by_date(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b1c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketizing equivalent key group: {'postHistory.PostId', 'posts.Id', 'tags.ExcerptPostId', 'postLinks.RelatedPostId', 'comments.PostId', 'postLinks.PostId', 'votes.PostId'}\n",
      "bucketizing equivalent key group: {'badges.UserId', 'comments.UserId', 'votes.UserId', 'postHistory.UserId', 'posts.OwnerUserId', 'users.Id'}\n",
      "badges\n",
      "Discretizing table takes 0.044840097427368164 secs\n",
      "Structure learning took 1.7565624713897705 secs.\n",
      "done, parameter learning took 0.16778016090393066 secs.\n",
      "votes\n",
      "Discretizing table takes 2.4288737773895264 secs\n",
      "Structure learning took 10.895316123962402 secs.\n",
      "done, parameter learning took 0.09624958038330078 secs.\n",
      "postHistory\n",
      "Discretizing table takes 0.0911564826965332 secs\n",
      "Structure learning took 11.851043462753296 secs.\n",
      "done, parameter learning took 0.14274191856384277 secs.\n",
      "posts\n",
      "Discretizing table takes 0.4713270664215088 secs\n",
      "Structure learning took 11.854781150817871 secs.\n",
      "done, parameter learning took 0.19270777702331543 secs.\n",
      "users\n",
      "Discretizing table takes 2.426241397857666 secs\n",
      "Structure learning took 2.5429205894470215 secs.\n",
      "done, parameter learning took 0.1537032127380371 secs.\n",
      "comments\n",
      "Discretizing table takes 0.16298365592956543 secs\n",
      "Structure learning took 7.335877180099487 secs.\n",
      "done, parameter learning took 0.12381649017333984 secs.\n",
      "postLinks\n",
      "Discretizing table takes 0.014145851135253906 secs\n",
      "Structure learning took 0.556511640548706 secs.\n",
      "done, parameter learning took 0.06967449188232422 secs.\n",
      "tags\n",
      "Discretizing table takes 0.008202314376831055 secs\n",
      "Structure learning took 0.025674104690551758 secs.\n",
      "done, parameter learning took 0.01674199104309082 secs.\n",
      "models save at /home/ubuntu/data_CE/CE_scheme_models/update/model_stats_sub_optimal_200.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/ubuntu/data_CE/CE_scheme_models/update/\"\n",
    "train_one_stats(\"stats\", data_folder, model_path, 200, \"sub_optimal\", True, actual_data=before_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb0bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path + \"buckets.pkl\", \"rb\") as f:\n",
    "    buckets = pickle.load(f)\n",
    "with open(model_path + \"model_stats_sub_optimal_200.pkl\", \"rb\") as f:\n",
    "    FJmodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/home/ubuntu/End-to-End-CardEst-Benchmark/workloads/stats_CEB/sub_plan_queries/stats_CEB_sub_queries.sql\"\n",
    "with open(query_file, \"r\") as f:\n",
    "    queries = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c67bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qerror = []\n",
    "latency = []\n",
    "pred = []\n",
    "for i, query_str in enumerate(queries):\n",
    "    query = query_str.split(\"||\")[0][:-1]\n",
    "    #print(\"========================\")\n",
    "    true_card = int(query_str.split(\"||\")[-1])\n",
    "    t = time.time()\n",
    "    res = FJmodel.get_cardinality_bound(query)\n",
    "    pred.append(res)\n",
    "    latency.append(time.time() - t)\n",
    "    qerror.append(res/true_card)\n",
    "    #print(f\"estimating query {i}: predicted {res}, true_card {true_card}, qerror {res/true_card}, latency {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99, 100]:\n",
    "    print(f\"q-error {i}% percentile is {np.percentile(qerror, i)}\")\n",
    "print(f\"total inference time: {np.sum(latency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3b6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags does not have data to update\n",
      "updating equivalent key group: {'postHistory.PostId', 'posts.Id', 'tags.ExcerptPostId', 'postLinks.RelatedPostId', 'comments.PostId', 'postLinks.PostId', 'votes.PostId'}\n",
      "tags.ExcerptPostId\n",
      "updating equivalent key group: {'badges.UserId', 'comments.UserId', 'votes.UserId', 'postHistory.UserId', 'posts.OwnerUserId', 'users.Id'}\n"
     ]
    }
   ],
   "source": [
    "table_buckets = FJmodel.table_buckets\n",
    "null_values = FJmodel.null_value\n",
    "data, table_buckets, null_values = update_stats_data(data_folder, model_path, buckets, table_buckets,\n",
    "                                                     null_values, False, after_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0cc589",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9e082cb4ed2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFJmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CE_scheme/BayesCard/Models/Bayescard_BN.py\u001b[0m in \u001b[0;36mupdate_from_data\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdiscrete_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_update_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Discretizing table took {time.time() - t} secs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CE_scheme/BayesCard/Models/BN_single_model.py\u001b[0m in \u001b[0;36mprocess_update_dataset\u001b[0;34m(self, data, n_bins, drop_na, ignore_cols)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mn_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mis_continuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdrop_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdrop_na\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 )\n\u001b[1;32m    103\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CE_scheme/BayesCard/Models/BN_single_model.py\u001b[0m in \u001b[0;36mdiscretize_series_based_on_existing\u001b[0;34m(self, series, col, n_bins, is_continuous, drop_na)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# map the original value to encoded value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mvalue_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mstart_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_val\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "for table in FJmodel.schema.tables:\n",
    "    t_name = table.table_name\n",
    "    if t_name in data and data[t_name] is not None:\n",
    "        bn = FJmodel.bns[t_name]\n",
    "        bn.null_values = null_values[t_name]\n",
    "        bn.update_from_data(data[t_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BayesCard.Models.Bayescard_BN import Bayescard_BN\n",
    "\n",
    "bn = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
