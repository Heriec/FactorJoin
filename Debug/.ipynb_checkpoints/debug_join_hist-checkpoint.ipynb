{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53641ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from Join_scheme.data_prepare import process_stats_data\n",
    "from BayesCard.Models.Bayescard_BN import Bayescard_BN\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BayesCard.Evaluation.cardinality_estimation import parse_query_single_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b523b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Join_scheme.data_prepare import process_stats_data\n",
    "data_path = \"/home/ubuntu/End-to-End-CardEst-Benchmark/datasets/stats_simplified/{}.csv\"\n",
    "model_folder = \"/home/ubuntu/data_CE/saved_models\"\n",
    "data, null_values, key_attrs, table_buckets, equivalent_keys, schema, bin_size, all_bin_means, all_bin_width = process_stats_data(data_path,\n",
    "                                                model_folder, 200, \"sub_optimal\", return_bin_means=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bin_means['tags.ExcerptPostId'] = np.ones(48)\n",
    "all_bin_width['tags.ExcerptPostId'] = np.ones(48) * len(data[\"tags\"][\"tags.ExcerptPostId\"])/48\n",
    "all_bin_means['posts.Id'] = np.ones(48)\n",
    "all_bin_width['posts.Id'] = np.ones(48) * len(data[\"posts\"][\"posts.Id\"])/48\n",
    "all_bin_means['users.Id'] = np.ones(107)\n",
    "all_bin_width['users.Id'] = np.ones(107) * len(data[\"users\"][\"users.Id\"])/107\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a02313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_histogram(data, key_attrs, all_bin_means, all_bin_width, all_bin_size, bin_size=50):\n",
    "    all_histogram = dict()\n",
    "    all_boundary = dict()\n",
    "    for table in data:\n",
    "        all_histogram[table] = dict()\n",
    "        all_boundary[table] = dict()\n",
    "        for attr in data[table]:\n",
    "            if attr in key_attrs[table]:\n",
    "                assert all_bin_size[table][attr] == len(all_bin_means[attr]) == len(all_bin_width[attr])\n",
    "            else:\n",
    "                hist, curr_bins = np.histogram(data[table][attr].values, bins=bin_size)\n",
    "                all_histogram[table][attr] = hist/np.sum(hist)\n",
    "                all_boundary[table][attr] = curr_bins\n",
    "    return all_histogram, all_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_histogram, all_boundary = learn_histogram(data, key_attrs, all_bin_means, all_bin_width, bin_size, bin_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from Join_scheme.join_graph import process_condition, get_join_hyper_graph\n",
    "from Join_scheme.data_prepare import identify_key_values\n",
    "from BayesCard.Evaluation.cardinality_estimation import timestamp_transorform, construct_table_query\n",
    "\n",
    "OPS = {\n",
    "    '>': np.greater,\n",
    "    '<': np.less,\n",
    "    '>=': np.greater_equal,\n",
    "    '<=': np.less_equal,\n",
    "    '=': np.equal,\n",
    "    '==': np.equal\n",
    "}\n",
    "\n",
    "class Bound_ensemble:\n",
    "    \"\"\"\n",
    "    This the class where we store all the trained models and perform inference on the bound.\n",
    "    \"\"\"\n",
    "    def __init__(self, hist, boundary, all_bin_means, all_key_size, schema):\n",
    "        self.hist = hist\n",
    "        self.boundary = boundary\n",
    "        self.schema = schema\n",
    "        self.all_bin_means = all_bin_means\n",
    "        self.all_key_size = all_key_size\n",
    "        self.all_keys, self.equivalent_keys = identify_key_values(schema)\n",
    "\n",
    "    def parse_query_simple(self, query):\n",
    "        \"\"\"\n",
    "        If your selection query contains no aggregation and nested sub-queries, you can use this function to parse a\n",
    "        join query. Otherwise, use parse_query function.\n",
    "        \"\"\"\n",
    "        query = query.replace(\" where \", \" WHERE \")\n",
    "        query = query.replace(\" from \", \" FROM \")\n",
    "        query = query.replace(\" and \", \" AND \")\n",
    "        query = query.split(\";\")[0]\n",
    "        query = query.strip()\n",
    "        tables_all = {}\n",
    "        join_cond = []\n",
    "        table_probs = {}\n",
    "        join_keys = {}\n",
    "        tables_str = query.split(\" WHERE \")[0].split(\" FROM \")[-1]\n",
    "        for table_str in tables_str.split(\",\"):\n",
    "            table_str = table_str.strip()\n",
    "            if \" as \" in table_str:\n",
    "                tables_all[table_str.split(\" as \")[-1]] = table_str.split(\" as \")[0]\n",
    "            else:\n",
    "                tables_all[table_str.split(\" \")[-1]] = table_str.split(\" \")[0]\n",
    "\n",
    "        # processing conditions\n",
    "        conditions = query.split(\" WHERE \")[-1].split(\" AND \")\n",
    "        for cond in conditions:\n",
    "            table, cond, join, join_key = process_condition(cond, tables_all)\n",
    "            if table not in table_probs:\n",
    "                table_probs[table] = 1\n",
    "            if not join:\n",
    "                attr = cond[0]\n",
    "                op = cond[1]\n",
    "                value = cond[2]\n",
    "                if \"Date\" in attr:\n",
    "                    assert \"::timestamp\" in value\n",
    "                    value = timestamp_transorform(value.strip().split(\"::timestamp\")[0])\n",
    "                curr_prob = 0\n",
    "                for i in range(0, len(self.boundary[table][attr])-1):\n",
    "                    if OPS[op](self.boundary[table][attr][i], value):\n",
    "                        curr_prob += self.hist[table][attr][i]\n",
    "                table_probs[table] *= curr_prob\n",
    "                #construct_table_query(self.bns[table], table_query[table], attr, op, value)\n",
    "            else:\n",
    "                join_cond.append(cond)\n",
    "                for tab in join_key:\n",
    "                    if tab in join_keys:\n",
    "                        join_keys[tab].add(join_key[tab])\n",
    "                    else:\n",
    "                        join_keys[tab] = set([join_key[tab]])\n",
    "        final_probs = 1\n",
    "        for table in table_probs:\n",
    "            final_probs *= table_probs[table]\n",
    "        #print(final_probs)\n",
    "        if final_probs == 0:\n",
    "            final_probs = 0.001\n",
    "        return tables_all, final_probs, join_cond, join_keys\n",
    "    \n",
    "    def multiply_hist_oned(self, all_probs, all_means):\n",
    "        all_probs = np.stack(all_probs, axis=0)\n",
    "        all_means = np.stack(all_means, axis=0)\n",
    "        multiplier = np.prod(all_means, axis=0)\n",
    "        min_number = np.amin(all_probs, axis=0)\n",
    "        multiplier = multiplier * min_number\n",
    "        return np.sum(multiplier)\n",
    "\n",
    "    def eliminate_one_key_group(self, key_group, relevant_keys, res):\n",
    "        all_means = []\n",
    "        all_probs = []\n",
    "        for key in relevant_keys:\n",
    "            if res:\n",
    "                hist = self.all_bin_means[key] * self.all_key_size[key]\n",
    "                #print(\"key\", np.sum(hist))\n",
    "                ratio = res/np.sum(hist)\n",
    "                all_means.append(self.all_bin_means[key]*ratio)\n",
    "                all_probs.append(self.all_key_size[key])\n",
    "            else:\n",
    "                #print(key, np.sum(self.all_bin_means[key] * self.all_key_size[key]))\n",
    "                all_means.append(self.all_bin_means[key])\n",
    "                all_probs.append(self.all_key_size[key])\n",
    "        return self.multiply_hist_oned(all_probs, all_means)\n",
    "        \n",
    "\n",
    "    def get_cardinality(self, query_str):\n",
    "        tables_all, table_probs, join_cond, join_keys = self.parse_query_simple(query_str)\n",
    "        equivalent_group = get_join_hyper_graph(join_keys, self.equivalent_keys)\n",
    "        res = None\n",
    "        for key_group in equivalent_group:\n",
    "            res = self.eliminate_one_key_group(key_group, equivalent_group[key_group], res)\n",
    "        if res <= 1:\n",
    "            res = 1\n",
    "        return res * table_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BE = Bound_ensemble(all_histogram, all_boundary, all_bin_means, all_bin_width, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/home/ubuntu/End-to-End-CardEst-Benchmark/workloads/stats_CEB/sub_plan_queries/stats_CEB_sub_queries.sql\"\n",
    "with open(query_file, \"r\") as f:\n",
    "    queries = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5394b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qerror = []\n",
    "latency = []\n",
    "pred = []\n",
    "for i, query_str in enumerate(queries):\n",
    "    #if i == 10: break\n",
    "    query = query_str.split(\"||\")[0][:-1]\n",
    "    print(\"========================\")\n",
    "    true_card = int(query_str.split(\"||\")[-1])\n",
    "    t = time.time()\n",
    "    res = BE.get_cardinality(query)\n",
    "    pred.append(res)\n",
    "    latency.append(time.time() - t)\n",
    "    qerror.append(res/true_card)\n",
    "    print(f\"estimating query {i}: predicted {res}, true_card {true_card}, qerror {res/true_card}, latency {time.time() - t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81df12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99, 100]:\n",
    "    print(f\"q-error {i}% percentile is {np.percentile(qerror, i)}\")\n",
    "print(f\"total inference time: {np.sum(latency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15202cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats_CEB_join_hist.txt\", \"w\") as f:\n",
    "    for p in pred:\n",
    "        f.write(str(p)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5bc33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
